\include{Sweave}
\documentclass [a4paper]{article}
%\VignetteIndexEntry{qfa}
\usepackage{url}
\usepackage{hyperref}            
\title{qfaBayes - An R package for Bayesian Quantitative Fitness Analysis}
\author{Jonathan Heydari}
\begin{document}
\setlength\parindent{0pt}
\maketitle

\section{Introduction}

Quantitative Fitness Analysis (QFA) is an experimental and computational workflow for comparing fitnesses of microbial cultures grown in parallel.  QFA can be applied to focused observations of single cultures but is most useful for genome-wide genetic interaction or drug screens investigating up to thousands of independent cultures.  The central experimental method is the inoculation of independent, dilute liquid microbial cultures onto solid agar plates which are incubated and regularly photographed. Photographs from each time-point are analyzed, producing quantitative cell density estimates, which are used to construct growth curves, allowing quantitative fitness measures to be derived. Culture fitnesses can be compared to quantify and rank genetic interaction strengths or drug sensitivities. The effect on culture fitness of any treatments added into substrate agar (e.g. small molecules, antibiotics or nutrients) or applied to plates externally (e.g. UV irradiation, temperature) can be quantified by QFA.

Detailed descriptions of how to carry out QFA experiments are available in open access articles, particularly in \href{http://dx.doi.org/10.3791/4018}{Banks et al. (2012)} and  \href{http://dx.doi.org/10.1371/journal.pgen.1001362}{Addinall et al. (2011)}. The purpose of this document is to describe, in detail, the functions for carrying out the Bayesian hierarchical models available in the qfaBayes R package for estimating fitnesses and inferring genetic
interactions.

\section{QFA data}

The raw experimental data generated by QFA consists of timeseries photographs of cultures growing on agar plates.  The first step in the computational component of the QFA workflow is to convert these photographic observations into cell density estimates for cultures in each position on each plate analysed. The Colonyzer image analysis tool (\href{http://dx.doi.org/10.1186/1471-2105-11-287}{Lawless et al. (2010)}) is designed for this task and can be downloaded from its \href{http://research.ncl.ac.uk/colonyzer/}{website}. Once all the images have been successfully analysed, the next step is to use the qfaBayes R package to associate culture locations with genotypes and to construct growth curves (cell density estimates over time) for each culture.

\section{Installing the qfaBayes package}

The qfaBayes package source code is available for download from \href{http://r-forge.r-project.org/projects/qfa}{R-Forge}, and so it should be possible to install the latest version using the R package management system on a wide range of operating systems by executing the following command within an R environment: 
\begin{verbatim}
install.packages("qfaBayes",repos="http://r-forge.r-project.org")
\end{verbatim}

Once installed, the package can be loaded ready for use with
\begin{verbatim}
library(qfaBayes)
\end{verbatim}

Please note that this installation method will typically only work using the latest version of R (which can be freely downloaded from the R \href{http://www.r-project.org/}{website}).  Alternatively, instructions for accessing the source code for the package from are available \href{http://r-forge.r-project.org/scm/?group_id=880}{here}.

\section{Function documentation}

The following command will provide an overview of functions available within the qfaBayes package together with brief descriptions of what they do and links to detailed descriptions indicating input arguments and output:
\begin{verbatim}
help(package="qfaBayes")
\end{verbatim}
This document can be accessed at any time with:
\begin{verbatim}
vignette("qfaBayes")
\end{verbatim}

\section{General overview}

This R package is intended to fit the three Bayesian Models described in J Heydari, C Lawless, D Lydall and D J Wilkinson. \emph{Bayesian hierarchical modelling for inferring genetic interactions in yeast. Journal of the Royal Statistical Society: Series C (Applied Statistics)}, in submission.
Their are three Bayesian models available in the qfaBayes package: the separate hierarchical model (SHM), interaction hierarchical model (IHM), and joint hierarchical model (JHM).
There are three demos included in this package (\verb$SHM$, \verb$IHM$ and \verb$JHM$).

Computational time for a typical QFA dataset and the Bayesian models in the qfaBayes package can range from days to weeks.
Variables \verb$burn$, \verb$iter$ and \verb$thin$ control the burn-in period, output sample size and thinning. Different QFA datasets to those used in the qfaBayes demos may require different values for \verb$burn$, \verb$iter$ and \verb$thin$, typically the variables are increased as the size of the dataset is increased. 

\subsection{SHM}
\verb$SHM$
This demo runs the SHM for the $\emph{ura3}\Delta$ data set at $27\,^{\circ}\mathrm{C}$ trimmed to only include plate 15, which accounts for only 50 of the 4294 $\emph{orf}\Delta$s available.
It is expected that you will wish to create ouput with larger sample size, burn in period and thinning, to do this simply copy all the code from the demo and change the variables \verb$burn$, \verb$iter$ and \verb$thin$.

The typical model computation time of the SHM alone is one week with burn-in of 600000, sample size of 1000 and thinning of 100.

A more detailed workflow which is compatible with the standalone C code is given in demo \verb$SHM_C$.

\subsection{IHM}
\verb$IHM$
This demo runs the SHM for the $\emph{ura3}\Delta$ data set at $27\,^{\circ}\mathrm{C}$, trimmed to only include plate 15, which accounts for only 50 of the 4294 $\emph{orf}\Delta$s available.
Next, the SHM is then run for the $\emph{cdc13-1}\Delta$ data set at $27\,^{\circ}\mathrm{C}$, trimmed to only include plate 15, which accounts for only 50 of the 4294 $\emph{orf}\Delta$s available.
The IHM is then run using the output from the SHM output for the two data sets.
Finally you will be asked if you wish to create a fitness plot with your results.

It is expected that you will wish to create ouput with larger sample size, burn in period and thinning, to do this simply copy all the code from the demo and change the variables \verb$burn$, \verb$iter$ and \verb$thin$ where they appear.
The typical model computation time of the IHM alone is one day with burn-in of 600000, sample size of 1000 and thinning of 100.

A more detailed work-flow which is compatible with the standalone C code is given in demo \verb$IHM_C$.

\subsection{JHM}
\verb$JHM$
This demo runs the JHM for the $\emph{ura3}\Delta$ and $\emph{cdc13-1}\Delta$ data sets, both at $27\,^{\circ}\mathrm{C}$, trimmed to only include plate 15, which accounts for only 50 of the 4294 $\emph{orf}\Delta$s available.
At the end of the demo you will be asked if you wish to create a fitness plot with your results.

It is expected that you will wish to create ouput with larger sample size, burn in period and thinning, to do this simply copy all the code from the demo and change the variables \verb$burn$, \verb$iter$ and \verb$thin$ where they appear.
The typical model computation time of the JHM alone is two weeks with burn-in of 800000, sample size of 5000 and thinning of 10.

A more detailed work-flow which is compatible with the standalone C code is given in demo \verb$JHM_C$.

\section{Demos}
\subsection{SHM demo}
To see how the \verb$SHM$ demo works the following detailed explaination is provided and is to be used in conjunction with the R package manual.
The \verb$SHM$ demo runs the following commands:
\\
\\
\verb@> data("URA3_Raw_extratrim_15")@\\
\verb@> a<-a_15@\\
\\
The above commands load a trimmed ura3Del data set consisting of only of master plate 15 to the variable \verb$a_15$ and copys this to a variable "a".
\\
\\
\verb@> qfa.variables(a)@\\
\\
The above command lists the avalible options for the treatment, screen number and master plate.
\\
\\
\verb@> Treatment<-27@\\
\verb@> Screen<-unique(a$Screen.Name)@\\
\verb@> MPlate<-15@\\
\verb@> remove_row<-c(1,16)@\\
\verb@> remove_col<-c(1,24)@\\
\verb@> SHM<-SHM_postpro(a=a,Treatment=Treatment,Screen=Screen,MPlate=MPlate,@\\
\verb@>   remove_row=remove_row,remove_col=remove_col)@\\
\\
The above commands loads a broad set of prior values for the SHM to the variable \verb$priors_SHM$ and then copys this to variable PRIORS.
\\
\\
\verb@> data("priors_SHM")@\\
\verb@> PRIORS<-priors_SHM[[1]]@\\
\verb@> data("tuning_SHM")@\\
\verb@> TUNING<-tuning_SHM[[1]]@\\
\\
The above command selects all screens for the following SHM analysis.
\\
\\
\verb@> burn<-600000@\\
\verb@> iters<-1000@\\
\verb@> thin<-100@\\
\\
The above command runs the post processing for the SHM, organising the Colonyser ouput in variable \verb$a$ for use with the SHM.
The dataset will be trimmed to only include the data corresponding to the specified \verb$Treat$, \verb$Screen$ and \verb$MPlate$.
\\
\\
\verb@> SHM_output<-SHM_main(burn=burn,iters=iters,thin=thin,QFA.I=SHM$QFA.I,@\\
\verb@>   QFA.y=SHM$QFA.y,QFA.x=SHM$QFA.x,QFA.NoORF=SHM$QFA.NoORF,@\\
\verb@>   QFA.NoTIME=SHM$QFA.NoTIME,PRIORS=PRIORS,TUNING=TUNING)@\\
\\
The above command runs the C code for the SHM in R. \verb$burn$, \verb$iters$ and \verb$thin$ which have all been set to 1 for the purpose of the demo.
\verb$CAPL$ is the number of orfs for the SHM to proform the analysis on.
The output \verb$SHM_output$ will be a table of posterior samples, where each coloumn corresponds to a different model paramater; a table header is included to idendify each coloumn.
The above command will ask the user if they would like an example of some plots created form the posterior sample.
\\
\\
\verb@> plot_SHM_simple(SHM_output,SHM)@\\
\\
The above commands outputs fitted logistic growth curve plots for each ORF, where black is for the repeat fitted curves and red for orf level fitted curves.

\subsection{IHM demo}
abc
\\
\\
\verb@> data("URA3_Raw_extratrim_15")@\\
\verb@> a<-a_15@\\
\verb@> data("CDC13-1_Raw_extratrim_15")@\\
\verb@> b<-b_15@\\
\\
abc
\\
\\
\verb@> qfa.variables(a)@\\
\verb@> qfa.variables(b)@\\
\\
abc
\\
\\
\verb@> Treatment_a=27@\\
\verb@> Screen_a<-unique(a$Screen.Name)@\\
\verb@> MPlate_a<-15@\\
\verb@> Treatment_b=27@\\
\verb@> Screen_b<-unique(b$Screen.Name)@\\
\verb@> MPlate_b<-15@\\
\verb@> SHM_a<-SHM_postpro(a=a,Treatment=Treatment_a,Screen=Screen_a,MPlate=MPlate_a)@\\
\verb@> SHM_b<-SHM_postpro(a=b,Treatment=Treatment_b,Screen=Screen_b,MPlate=MPlate_b)@\\
\\
abc
\\
\\
\verb@> data("priors_SHM")@\\
\verb@> PRIORS=priors_SHM[[1]]@\\
\verb@> data("tuning_SHM")@\\
\verb@> TUNING=tuning_SHM[[1]]@\\
\\
abc
\\
\\
\verb@> burn<-600000@\\
\verb@> iters<-1000@\\
\verb@> thin<-100@\\
\\
abc
\\
\\
\verb@> SHM_output_a<-SHM_main(burn=burn,iters=iters,thin=thin,QFA.I=SHM_a$QFA.I,@\\
\verb@>   QFA.y=SHM_a$QFA.y,QFA.x=SHM_a$QFA.x,QFA.NoORF=SHM_a$QFA.NoORF,@\\
\verb@>   QFA.NoTIME=SHM_a$QFA.NoTIME,PRIORS=PRIORS,TUNING=TUNING)@\\
\verb@> SHM_output_b<-SHM_main(burn=burn,iters=iters,thin=thin,QFA.I=SHM_b$QFA.I,@\\
\verb@>   QFA.y=SHM_b$QFA.y,QFA.x=SHM_b$QFA.x,QFA.NoORF=SHM_b$QFA.NoORF,@\\
\verb@>   QFA.NoTIME=SHM_b$QFA.NoTIME,PRIORS=PRIORS,TUNING=TUNING)@\\
\\
abc
\\
\\
\verb@> SHM_a$QFA.yA=colMeans(SHM_output_a)@\\
\verb@> SHM_b$QFA.yB=colMeans(SHM_output_b)@\\
\\
abc
\\
\\
\verb@> data("priors_IHM")@\\
\verb@> PRIORS_IHM=priors_IHM[[1]]@\\
\verb@> data("tuning_IHM")@\\
\verb@> TUNING_IHM=tuning_IHM[[1]]@\\
\\
abc
\\
\\
\verb@> burn_IHM<-500000@\\
\verb@> iters_IHM<-1000@\\
\verb@> thin_IHM<-100@\\
\\
abc
\\
\\
\verb@> IHM_output=IHM_main(burn=burn_IHM,iters=iters_IHM,thin=thin_IHM,@\\
\verb@>   QFA.IA=SHM_a$QFA.I,QFA.yA=SHM_a$QFA.yA,QFA.NoORFA=SHM_a$QFA.NoORF,@\\
\verb@>   QFA.IB=SHM_b$QFA.I,QFA.yB=SHM_b$QFA.yB,QFA.NoORFB=SHM_b$QFA.NoORF,@\\
\verb@>   PRIORS=PRIORS_IHM,TUNING=TUNING_IHM)@\\
\\
abc
\\
\\
\verb@> plot_IHM_simple(IHM_output,SHM_a)@\\
\\
abc
\subsection{JHM demo}
abc
\\
\\
\verb@> data("URA3_Raw_extratrim_15")@\\
\verb@> a<-a_15@\\
\verb@> data("CDC13-1_Raw_extratrim_15")@\\
\verb@> b<-b_15@\\
\\
abc
\\
\\
\verb@> qfa.variables(a)@\\
\verb@> qfa.variables(b)@\\
\\
abc
\\
\\
\verb@> Treatment_a=27@\\
\verb@> Screen_a<-unique(a$Screen.Name)@\\
\verb@> MPlate_a<-15@\\
\verb@> Treatment_b=27@\\
\verb@> Screen_b<-unique(b$Screen.Name)@\\
\verb@> MPlate_b<-15@\\
\verb@> remove_row<-c(1,16)@\\
\verb@> remove_col<-c(1,24)@\\
\verb@> JHM<-JHM_postpro(a,Treatment_a=Treatment_a,Screen_a=Screen_a,MPlate_a,b,@\\
\verb@>   Treatment_b=Treatment_b,Screen_b=Screen_b,MPlate_b=MPlate_b,@\\
\verb@>   remove_row=remove_row,remove_col=remove_col)@\\
\\
abc
\\
\\
\verb@> data("priors_JHM")@\\
\verb@> PRIORS=priors_JHM[[1]]@\\
\verb@> data("tuning_JHM")@\\
\verb@> TUNING=tuning_JHM[[1]]@\\
\\
abc
\\
\\
\verb@> burn<-800000@\\
\verb@> iters<-5000@\\
\verb@> thin<-10@\\
\\
abc
\\
\\
\verb@> JHM_output<-JHM_main(burn=burn,iters=iters,thin=thin,QFA.IA=JHM$QFA.IA,@\\
\verb@>   QFA.yA=JHM$QFA.yA,QFA.xA=JHM$QFA.xA,QFA.NoORFA=JHM$QFA.NoORFA,@\\
\verb@>   QFA.NoTIMEA=JHM$QFA.NoTIMEA,QFA.IB=JHM$QFA.IB,QFA.yB=JHM$QFA.yB,@\\
\verb@>   QFA.xB=JHM$QFA.xB,QFA.NoORFB=JHM$QFA.NoORFB,QFA.NoTIMEB=JHM$QFA.NoTIMEB,@\\
\verb@>   PRIORS=PRIORS,TUNING=TUNING)@\\
\\
abc
\\
\\
\verb@> plot_JHM_simple(JHM_output,JHM)@\\
\\
\end{document}
% eof
